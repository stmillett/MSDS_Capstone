{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNS_file_length = 40821591\n",
    "flows_file_length = 129977412\n",
    "proc_file_length = 426045096\n",
    "auth_file_length = 1051430459\n",
    "redteam_file_length = 749\n",
    "time_start = 86400\n",
    "time_end = 259200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNS_Names = [\"time\",\"src_comp\",\"comp_rslv\"]\n",
    "flows_Names = [\"time\",\"dur\",\"src_comp\",\"src_port\",\"dest_comp\",\n",
    "               \"dest_port\",\"protocol\",\"pkt_cnt\",\"byte_cnt\"]\n",
    "auth_Names = [\"time\",\"user@domain\",\"dest_user@domain\",\"src_comp\",\n",
    "              \"dest_comp\",\"auth_type\",\"logon_type\",\"auth_orient\",\"success\"]\n",
    "proc_Names = [\"time\",\"user@domain\",\"src_comp\",\"proc\",\"start\"]\n",
    "redteam_Names = [\"time\",\"user@domain\",\"src_comp\",\"dest_comp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dns_save_filename = '/users7/csegrad/smillett/capstone/Dataset/reduced_dns.csv'\n",
    "switch = 0\n",
    "for i in range(BATCHES):\n",
    "    \n",
    "    DNS_range = int(DNS_file_length/BATCHES)\n",
    "    DNS_Data = pd.read_csv('/users7/csegrad/smillett/capstone/Dataset/dns.txt',names=DNS_Names, \n",
    "                           skiprows=i*DNS_range, nrows=DNS_range)\n",
    "    if DNS_Data.loc[DNS_range-1,'time']>time_start and DNS_Data.loc[0,'time']<time_end:\n",
    "        if switch == 0:\n",
    "            DNS_Data.to_csv(dns_save_filename,index=False)\n",
    "            switch = 1\n",
    "        else:\n",
    "            with open(dns_save_filename,'a') as f:\n",
    "                DNS_Data.to_csv(f, header=False,index=False)\n",
    "    elif DNS_Data.loc[0,'time']>time_end:\n",
    "        break\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     flows_range = int(flows_file_length/BATCHES)\n",
    "#     flows_Data = pd.read_csv('E:\\\\Data Science\\\\Capstone\\\\Dataset\\\\flows.txt',names=flows_Names, \n",
    "#                              skiprows=i*flows_range, nrows=flows_range)\n",
    "    \n",
    "#     proc_range = int(auth_file_length/BATCHES)\n",
    "#     proc_Data = pd.read_csv('E:\\\\Data Science\\\\Capstone\\\\Dataset\\\\proc.txt',names=proc_Names, \n",
    "#                             skiprows=i*proc_range, nrows=proc_range)\n",
    "    \n",
    "#     auth_range = int(auth_file_length/BATCHES)\n",
    "#     auth_Data = pd.read_csv('E:\\\\Data Science\\\\Capstone\\\\Dataset\\\\auth.txt',names=auth_Names, \n",
    "#                             skiprows=i*proc_range, nrows=auth_range)\n",
    "    \n",
    "#     master_data = pd.concat([DNS_Data,flows_Data,proc_Data,auth_Data], sort=False)\n",
    "    \n",
    "    \n",
    "#     master_group = master_data.groupby('time')\n",
    "    \n",
    "#     failed_logon = master_group['success'].apply(lambda x: (x=='Fail').sum()).reset_index(name='failed_logon')\n",
    "    \n",
    "#     TGS_logon = master_group['auth_orient'].apply(lambda x: (x=='TGS').sum()).reset_index(name='TGS_auth')\n",
    "#     TGT_logon = master_group['auth_orient'].apply(lambda x: (x=='TGT').sum()).reset_index(name='TGS_auth')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#redteam_Data = pd.read_csv('E:\\\\Data Science\\\\Capstone\\\\Dataset\\\\redteam.txt',names=redteam_Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n"
     ]
    }
   ],
   "source": [
    "auth_save_filename = '/users7/csegrad/smillett/capstone/Dataset/reduced_auth.csv'   \n",
    "switch = 0\n",
    "for i in range(BATCHES):\n",
    "    \n",
    "    auth_range = int(auth_file_length/BATCHES)\n",
    "    auth_Data = pd.read_csv('/users7/csegrad/smillett/capstone/Dataset/auth.txt',names=auth_Names, \n",
    "                           skiprows=i*auth_range, nrows=auth_range)\n",
    "    if auth_Data.loc[auth_range-1,'time']>time_start and auth_Data.loc[0,'time']<time_end:\n",
    "        if switch == 0:\n",
    "            print('started')\n",
    "            auth_Data.to_csv(auth_save_filename,index=False)\n",
    "            switch = 1\n",
    "        else:\n",
    "            with open(auth_save_filename,'a') as f:\n",
    "                auth_Data.to_csv(f, header=False,index=False)\n",
    "    elif auth_Data.loc[0,'time']>time_end:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n"
     ]
    }
   ],
   "source": [
    "proc_save_filename = '/users7/csegrad/smillett/capstone/Dataset/reduced_proc.csv'   \n",
    "switch = 0\n",
    "for i in range(BATCHES):\n",
    "    \n",
    "    proc_range = int(proc_file_length/BATCHES)\n",
    "    proc_Data = pd.read_csv('/users7/csegrad/smillett/capstone/Dataset/proc.txt',names=proc_Names, \n",
    "                           skiprows=i*proc_range, nrows=proc_range)\n",
    "    if proc_Data.loc[proc_range-1,'time']>time_start and proc_Data.loc[0,'time']<time_end:\n",
    "        if switch == 0:\n",
    "            print('started')\n",
    "            proc_Data.to_csv(proc_save_filename,index=False)\n",
    "            switch = 1\n",
    "        else:\n",
    "            with open(proc_save_filename,'a') as f:\n",
    "                proc_Data.to_csv(f, header=False,index=False)\n",
    "    elif proc_Data.loc[0,'time']>time_end:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27643\n",
      "36166\n",
      "44547\n",
      "54710\n",
      "64720\n",
      "80172\n",
      "93921\n",
      "started\n",
      "105193\n",
      "116405\n",
      "125147\n",
      "133468\n",
      "142042\n",
      "153061\n",
      "168343\n",
      "184923\n",
      "199592\n",
      "209131\n",
      "218272\n",
      "229811\n",
      "246284\n",
      "263548\n",
      "281061\n"
     ]
    }
   ],
   "source": [
    "flows_save_filename = '/users7/csegrad/smillett/capstone/Dataset/reduced_flows.csv'    \n",
    "switch = 0\n",
    "for i in range(BATCHES):\n",
    "    \n",
    "    flows_range = int(flows_file_length/BATCHES)\n",
    "    flows_Data = pd.read_csv('/users7/csegrad/smillett/capstone/Dataset/flows.txt',names=flows_Names, \n",
    "                           skiprows=i*flows_range, nrows=flows_range)\n",
    "    if flows_Data.loc[flows_range-1,'time']>time_start and flows_Data.loc[0,'time']<time_end:\n",
    "        if switch == 0:\n",
    "            print('started')\n",
    "            flows_Data.to_csv(flows_save_filename,index=False)\n",
    "            switch = 1\n",
    "        else:\n",
    "            with open(flows_save_filename,'a') as f:\n",
    "                flows_Data.to_csv(f, header=False,index=False)\n",
    "    elif flows_Data.loc[0,'time']>time_end:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
