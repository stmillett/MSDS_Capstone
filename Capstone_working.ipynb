{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as spark\n",
    "import datetime, time\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from pyspark.sql.types import (StructField, StringType,FloatType, \n",
    "                               DoubleType, IntegerType, StructType,\n",
    "                              DateType)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame as spDataFrame\n",
    "from pyspark.ml.feature import Binarizer, OneHotEncoder, StringIndexer\n",
    "import os\n",
    "#from tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionAll(*dfs):\n",
    "    return reduce(spDataFrame.unionAll, dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('Python Spark SQL basic example') \\\n",
    "        .config('spark.some.config.option','some-value') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data_schema = [StructField('time',IntegerType(),True),\n",
    "                   StructField('user@domain',StringType(),True),\n",
    "                   StructField('src_comp',StringType(),True),\n",
    "                   StructField('proc_name',StringType(),True),\n",
    "                   StructField('strt',StringType())]\n",
    "proc_final_struc = StructType(fields = proc_data_schema)\n",
    "proc = spark.read.csv('/users7/csegrad/smillett/capstone/Dataset/proc.txt',schema=proc_final_struc)\n",
    "\n",
    "auth_data_schema = [StructField('time',IntegerType(),True),\n",
    "                   StructField('src_user@domain',StringType(),True),\n",
    "                   StructField('dest_user@domain',StringType(),True),\n",
    "                   StructField('src_comp',StringType(),True),\n",
    "                   StructField('dest_comp',StringType(),True),\n",
    "                   StructField('auth_type',StringType(),True),\n",
    "                   StructField('logon_type',StringType(),True),\n",
    "                   StructField('auth_orient',StringType(),True),\n",
    "                   StructField('success',StringType(),True)]\n",
    "auth_final_struc = StructType(fields = auth_data_schema)\n",
    "auth = spark.read.csv('/users7/csegrad/smillett/capstone/Dataset/auth.txt',schema=auth_final_struc )\n",
    "\n",
    "flows_data_schema = [StructField('time',IntegerType(),False),\n",
    "                   StructField('dur',IntegerType(),False),\n",
    "                   StructField('src_comp',StringType(),False),\n",
    "                   StructField('src_port',StringType(),False),\n",
    "                   StructField('dest_comp',StringType(),False),\n",
    "                   StructField('dest_port',StringType(),False),\n",
    "                   StructField('protocol',StringType(),False),\n",
    "                   StructField('pkt_cnt',IntegerType(),False),\n",
    "                   StructField('byte_cnt',IntegerType(),False)]\n",
    "flows_final_struc = StructType(fields = flows_data_schema)\n",
    "flows = spark.read.csv('/users7/csegrad/smillett/capstone/Dataset/flows.txt',schema=flows_final_struc )\n",
    "\n",
    "dns_data_schema = [StructField('time',IntegerType(),True),\n",
    "                   StructField('src_comp',StringType(),True),\n",
    "                   StructField('cmp_resolved',StringType(),True)]\n",
    "dns_final_struc = StructType(fields = dns_data_schema)\n",
    "dns = spark.read.csv('/users7/csegrad/smillett/capstone/Dataset/dns.txt',schema=dns_final_struc)\n",
    "\n",
    "redteam_data_schema = [StructField('time',IntegerType(),True),\n",
    "                   StructField('user@domain',StringType(),True),\n",
    "                   StructField('src_comp',StringType(),True),\n",
    "                   StructField('dest_comp',StringType(),True)]\n",
    "redteam_final_struc = StructType(fields = redteam_data_schema)\n",
    "redteam = spark.read.csv('/users7/csegrad/smillett/capstone/Dataset/redteam.txt',schema=redteam_final_struc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_split = F.split(proc['user@domain'],'@')\n",
    "proc = proc.withColumn('src_user',proc_split.getItem(0))\n",
    "proc = proc.withColumn('src_dmn',proc_split.getItem(1))\n",
    "proc = proc.drop('user@domain')\n",
    "\n",
    "proc = proc.withColumn('type',F.lit('Process'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_src_split = F.split(auth['src_user@domain'],'@')\n",
    "auth = auth.withColumn('src_user',auth_src_split.getItem(0))\n",
    "auth = auth.withColumn('src_dmn',auth_src_split.getItem(1))\n",
    "\n",
    "auth_dest_split = F.split(auth['dest_user@domain'],'@')\n",
    "auth = auth.withColumn('dest_user',auth_dest_split.getItem(0))\n",
    "auth = auth.withColumn('dest_dmn',auth_dest_split.getItem(1))\n",
    "\n",
    "auth = auth.drop('src_user@domain','dest_user@domain')\n",
    "\n",
    "auth = auth.withColumn('type',F.lit('Auth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "redteam_split = F.split(redteam['user@domain'],'@')\n",
    "redteam = redteam.withColumn('src_user',redteam_split.getItem(0))\n",
    "redteam = redteam.withColumn('src_dmn',redteam_split.getItem(1))\n",
    "\n",
    "redteam = redteam.drop('user@domain')\n",
    "\n",
    "redteam = redteam.withColumn('type',F.lit('RedTeam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flows = flows.withColumn('avg_pkt_size', (flows['byte_cnt']/flows['pkt_cnt']).cast(DoubleType()))\n",
    "flows = flows.na.drop(how='all')\n",
    "\n",
    "flows = flows.withColumn('type',F.lit('DataFlow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colum = proc.columns\n",
    "# colum.sort()\n",
    "\n",
    "# proc = proc.select(colum)\n",
    "# redteam = redteam.select(colum)\n",
    "# auth = auth.select(colum)\n",
    "# flows = flows.select(colum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master = unionAll(redteam,auth,proc,flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(master.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master.select('strt').sort('strt').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redteam1 = redteam.rdd.map(lambda x: (x['time'], time.strftime('%m/%d %H:%M:%S', time.gmtime(x['time']) ))).toDF(['time','timestam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+---------+----------+-----------+-------+---------------+-------+---------------+--------+----+\n",
      "|time|src_comp|dest_comp|auth_type|logon_type|auth_orient|success|       src_user|src_dmn|      dest_user|dest_dmn|type|\n",
      "+----+--------+---------+---------+----------+-----------+-------+---------------+-------+---------------+--------+----+\n",
      "|   1|   C1250|     C586|     NTLM|   Network|      LogOn|Success|ANONYMOUS LOGON|   C586|ANONYMOUS LOGON|    C586|Auth|\n",
      "|   1|    C586|     C586|        ?|   Network|     LogOff|Success|ANONYMOUS LOGON|   C586|ANONYMOUS LOGON|    C586|Auth|\n",
      "|   1|    C988|     C988|        ?|   Network|     LogOff|Success|          C101$|   DOM1|          C101$|    DOM1|Auth|\n",
      "|   1|   C1020|    C1020|Negotiate|   Service|      LogOn|Success|         C1020$|   DOM1|         SYSTEM|   C1020|Auth|\n",
      "|   1|   C1021|     C625| Kerberos|   Network|      LogOn|Success|         C1021$|   DOM1|         C1021$|    DOM1|Auth|\n",
      "|   1|   C1035|     C586| Kerberos|   Network|      LogOn|Success|         C1035$|   DOM1|         C1035$|    DOM1|Auth|\n",
      "|   1|    C586|     C586|        ?|   Network|     LogOff|Success|         C1035$|   DOM1|         C1035$|    DOM1|Auth|\n",
      "|   1|   C1069|    C1069|Negotiate|   Service|      LogOn|Success|         C1069$|   DOM1|         SYSTEM|   C1069|Auth|\n",
      "|   1|   C1085|     C612| Kerberos|   Network|      LogOn|Success|         C1085$|   DOM1|         C1085$|    DOM1|Auth|\n",
      "|   1|    C612|     C612|        ?|   Network|     LogOff|Success|         C1085$|   DOM1|         C1085$|    DOM1|Auth|\n",
      "|   1|   C1151|    C1151|Negotiate|   Service|      LogOn|Success|         C1151$|   DOM1|         SYSTEM|   C1151|Auth|\n",
      "|   1|   C1154|    C1154|Negotiate|   Service|      LogOn|Success|         C1154$|   DOM1|         SYSTEM|   C1154|Auth|\n",
      "|   1|    C625|     C625|        ?|   Network|     LogOff|Success|         C1164$|   DOM1|         C1164$|    DOM1|Auth|\n",
      "|   1|    C119|     C528| Kerberos|   Network|      LogOn|Success|          C119$|   DOM1|          C119$|    DOM1|Auth|\n",
      "|   1|   C1218|     C529| Kerberos|   Network|      LogOn|Success|         C1218$|   DOM1|         C1218$|    DOM1|Auth|\n",
      "|   1|    C586|     C586|        ?|   Network|     LogOff|Success|         C1235$|   DOM1|         C1235$|    DOM1|Auth|\n",
      "|   1|   C1241|    C1241|Negotiate|   Service|      LogOn|Success|         C1241$|   DOM1|         SYSTEM|   C1241|Auth|\n",
      "|   1|   C1250|     C586| Kerberos|   Network|      LogOn|Success|         C1250$|   DOM1|         C1250$|    DOM1|Auth|\n",
      "|   1|   C1314|     C467| Kerberos|   Network|      LogOn|Success|         C1314$|   DOM1|         C1314$|    DOM1|Auth|\n",
      "|   1|    C144|     C144|Negotiate|   Service|      LogOn|Success|          C144$|   DOM1|         SYSTEM|    C144|Auth|\n",
      "+----+--------+---------+---------+----------+-----------+-------+---------------+-------+---------------+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auth.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+--------+-------+-------+\n",
      "|  time|src_comp|dest_comp|src_user|src_dmn|   type|\n",
      "+------+--------+---------+--------+-------+-------+\n",
      "|150885|  C17693|    C1003|    U620|   DOM1|RedTeam|\n",
      "|151036|  C17693|     C305|    U748|   DOM1|RedTeam|\n",
      "|151648|  C17693|     C728|    U748|   DOM1|RedTeam|\n",
      "|151993|  C17693|    C1173|   U6115|   DOM1|RedTeam|\n",
      "|153792|  C17693|     C294|    U636|   DOM1|RedTeam|\n",
      "|155219|  C17693|    C5693|    U748|   DOM1|RedTeam|\n",
      "|155399|  C17693|     C152|    U748|   DOM1|RedTeam|\n",
      "|155460|  C17693|    C2341|    U748|   DOM1|RedTeam|\n",
      "|155591|  C17693|     C332|    U748|   DOM1|RedTeam|\n",
      "|156658|  C17693|    C4280|    U748|   DOM1|RedTeam|\n",
      "|210086|  C18025|    C1493|    U748|   DOM1|RedTeam|\n",
      "|210294|  C18025|    C1493|    U748|   DOM1|RedTeam|\n",
      "|210312|  C18025|    C1493|    U748|   DOM1|RedTeam|\n",
      "|218418|  C17693|     C504|    U748|   DOM1|RedTeam|\n",
      "|227052|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "|227408|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "|227520|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "|227780|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "|228024|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "|228150|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "+------+--------+---------+--------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "redteam.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------+\n",
      "|   time|src_comp|cmp_resolved|\n",
      "+-------+--------+------------+\n",
      "|2289058|  C17693|       C5808|\n",
      "|2289207|  C17693|       C5808|\n",
      "|2289208|  C17693|       C5808|\n",
      "|2289209|  C17693|       C5808|\n",
      "|2289210|  C17693|       C5808|\n",
      "|2289212|  C17693|       C5808|\n",
      "|2289213|  C17693|       C5808|\n",
      "|2289216|  C17693|       C5808|\n",
      "|2289217|  C17693|       C5808|\n",
      "|2289218|  C17693|       C5808|\n",
      "|2289219|  C17693|       C5808|\n",
      "|2289239|  C17693|       C5808|\n",
      "|2289240|  C17693|       C5808|\n",
      "|2289241|  C17693|       C5808|\n",
      "|2289243|  C17693|       C5808|\n",
      "|2289264|  C17693|       C5808|\n",
      "|2289266|  C17693|       C5808|\n",
      "|2289269|  C17693|       C5808|\n",
      "|2296865|  C17693|      C17679|\n",
      "|2296867|  C17693|      C17679|\n",
      "+-------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dns.filter((dns['src_comp']=='C17693')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-------+---------+--------+--------+-------+-------+------------+\n",
      "|time|duration|src_comp|src_prt|dest_comp|dest_prt|protocol|pkt_cnt|byt_cnt|avg_pkt_size|\n",
      "+----+--------+--------+-------+---------+--------+--------+-------+-------+------------+\n",
      "|   1|       0|   C1065|    389|    C3799|  N10451|       6|     10|   5323|      532.30|\n",
      "|   1|       0|   C1423|  N1136|    C1707|      N1|       6|      5|    847|      169.40|\n",
      "|   1|       0|   C1423|  N1142|    C1707|      N1|       6|      5|    847|      169.40|\n",
      "|   1|       0|  C14909|  N8191|    C5720|    2049|       6|      1|     52|       52.00|\n",
      "|   1|       0|  C14909|  N8192|    C5720|    2049|       6|      1|     52|       52.00|\n",
      "|   1|       0|  C14909|  N8193|    C5720|    2049|       6|      1|     52|       52.00|\n",
      "|   1|       0|   C1707|     N1|    C1423|   N1136|       6|      4|    414|      103.50|\n",
      "|   1|       0|   C1707|     N1|    C1423|   N1142|       6|      4|    413|      103.25|\n",
      "|   1|       0|   C1707|     N1|     C925|  N10487|       6|      4|    414|      103.50|\n",
      "|   1|       0|   C1707|     N1|     C925|  N10491|       6|      4|    413|      103.25|\n",
      "|   1|       0|   C3587|    N44|     C528|     N17|       1|      2|    120|       60.00|\n",
      "|   1|       0|   C3799| N10451|    C1065|     389|       6|     12|   3007|      250.58|\n",
      "|   1|       0|   C4879|  N2369|     C585|     139|       6|      1|     46|       46.00|\n",
      "|   1|       0|    C528|    N17|    C3587|     N17|       1|      2|    120|       60.00|\n",
      "|   1|       0|   C5720|   2049|   C14909|   N8191|       6|      1|     52|       52.00|\n",
      "|   1|       0|   C5720|   2049|   C14909|   N8192|       6|      1|     52|       52.00|\n",
      "|   1|       0|   C5720|   2049|   C14909|   N8193|       6|      1|     52|       52.00|\n",
      "|   1|       0|   C8177|  N7052|    C7632|     N77|       6|      1|     48|       48.00|\n",
      "|   1|       0|    C925| N10487|    C1707|      N1|       6|      4|    810|      202.50|\n",
      "|   1|       0|    C925| N10491|    C1707|      N1|       6|      4|    810|      202.50|\n",
      "+----+--------+--------+-------+---------+--------+--------+-------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#master.groupBy('time').count().show()\n",
    "\n",
    "failed_logon = auth.filter(auth.success=='Fail').groupby(auth.time,auth.auth_type,auth.logon_type).count().na.fill(0).sort('time')\n",
    "failed_logon = failed_logon.select(F.col('time'),F.col('auth_type'),F.col('logon_type'),F.col('count').alias('fail_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+--------------+----------+\n",
      "|time|auth_type|    logon_type|fail_count|\n",
      "+----+---------+--------------+----------+\n",
      "|   1|        ?|             ?|         7|\n",
      "|   1|Negotiate|         Batch|         1|\n",
      "|   2|        ?|             ?|         2|\n",
      "|   3|Negotiate|         Batch|         1|\n",
      "|   3|        ?|             ?|         1|\n",
      "|   4|Negotiate|         Batch|         1|\n",
      "|   4|        ?|             ?|         1|\n",
      "|   5|Negotiate|         Batch|         1|\n",
      "|   6|        ?|             ?|         1|\n",
      "|   7|Negotiate|         Batch|         1|\n",
      "|   8|Negotiate|         Batch|         1|\n",
      "|  11|     NTLM|       Network|         1|\n",
      "|  12|        ?|             ?|         1|\n",
      "|  13|        ?|             ?|         1|\n",
      "|  14|     NTLM|       Network|         1|\n",
      "|  15|Negotiate|         Batch|         1|\n",
      "|  16|        ?|             ?|         1|\n",
      "|  23|Negotiate|         Batch|         1|\n",
      "|  25|Negotiate|NewCredentials|         1|\n",
      "|  25|        ?|             ?|         2|\n",
      "+----+---------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "failed_logon.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_type =  auth.filter(auth.auth_orient=='TGT').groupby(auth.time).count().na.fill(0).sort('time')\n",
    "tgs_type =  auth.filter(auth.auth_orient=='TGS').groupby(auth.time).count().na.fill(0).sort('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_start = proc.groupby(proc.time).agg(F.when)\n",
    "process_start = process_start.a\n",
    "agg().sort('time')\n",
    "#process_start = process_start.select(F.col('time'),F.col('strt'),F.col('count').alias('proc_change'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+--------+-------+-------+-----------+-----------------+\n",
      "|  time|src_comp|dest_comp|src_user|src_dmn|   type|successType|       successVec|\n",
      "+------+--------+---------+--------+-------+-------+-----------+-----------------+\n",
      "|150885|  C17693|    C1003|    U620|   DOM1|RedTeam|       69.0| (300,[69],[1.0])|\n",
      "|151036|  C17693|     C305|    U748|   DOM1|RedTeam|      296.0|(300,[296],[1.0])|\n",
      "|151648|  C17693|     C728|    U748|   DOM1|RedTeam|      214.0|(300,[214],[1.0])|\n",
      "|151993|  C17693|    C1173|   U6115|   DOM1|RedTeam|      294.0|(300,[294],[1.0])|\n",
      "|153792|  C17693|     C294|    U636|   DOM1|RedTeam|       25.0| (300,[25],[1.0])|\n",
      "|155219|  C17693|    C5693|    U748|   DOM1|RedTeam|      240.0|(300,[240],[1.0])|\n",
      "|155399|  C17693|     C152|    U748|   DOM1|RedTeam|      293.0|(300,[293],[1.0])|\n",
      "|155460|  C17693|    C2341|    U748|   DOM1|RedTeam|      217.0|(300,[217],[1.0])|\n",
      "|155591|  C17693|     C332|    U748|   DOM1|RedTeam|      182.0|(300,[182],[1.0])|\n",
      "|156658|  C17693|    C4280|    U748|   DOM1|RedTeam|      239.0|(300,[239],[1.0])|\n",
      "|210086|  C18025|    C1493|    U748|   DOM1|RedTeam|       65.0| (300,[65],[1.0])|\n",
      "|210294|  C18025|    C1493|    U748|   DOM1|RedTeam|       65.0| (300,[65],[1.0])|\n",
      "|210312|  C18025|    C1493|    U748|   DOM1|RedTeam|       65.0| (300,[65],[1.0])|\n",
      "|218418|  C17693|     C504|    U748|   DOM1|RedTeam|      130.0|(300,[130],[1.0])|\n",
      "|227052|  C17693|     C148|    U748|   DOM1|RedTeam|       20.0| (300,[20],[1.0])|\n",
      "|227408|  C17693|     C148|    U748|   DOM1|RedTeam|       20.0| (300,[20],[1.0])|\n",
      "|227520|  C17693|     C148|    U748|   DOM1|RedTeam|       20.0| (300,[20],[1.0])|\n",
      "|227780|  C17693|     C148|    U748|   DOM1|RedTeam|       20.0| (300,[20],[1.0])|\n",
      "|228024|  C17693|     C148|    U748|   DOM1|RedTeam|       20.0| (300,[20],[1.0])|\n",
      "|228150|  C17693|     C148|    U748|   DOM1|RedTeam|       20.0| (300,[20],[1.0])|\n",
      "+------+--------+---------+--------+-------+-------+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndexer = StringIndexer(inputCol='dest_comp', outputCol='successType')\n",
    "model = stringIndexer.fit(redteam)\n",
    "indexed = model.transform(redteam)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol='successType', outputCol='successVec')\n",
    "encoded = encoder.transform(indexed)\n",
    "encoded.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+--------+-------+-------+\n",
      "|  time|src_comp|dest_comp|src_user|src_dmn|   type|\n",
      "+------+--------+---------+--------+-------+-------+\n",
      "|150885|  C17693|    C1003|    U620|   DOM1|RedTeam|\n",
      "|151036|  C17693|     C305|    U748|   DOM1|RedTeam|\n",
      "|151648|  C17693|     C728|    U748|   DOM1|RedTeam|\n",
      "|151993|  C17693|    C1173|   U6115|   DOM1|RedTeam|\n",
      "|153792|  C17693|     C294|    U636|   DOM1|RedTeam|\n",
      "|155219|  C17693|    C5693|    U748|   DOM1|RedTeam|\n",
      "|155399|  C17693|     C152|    U748|   DOM1|RedTeam|\n",
      "|155460|  C17693|    C2341|    U748|   DOM1|RedTeam|\n",
      "|155591|  C17693|     C332|    U748|   DOM1|RedTeam|\n",
      "|156658|  C17693|    C4280|    U748|   DOM1|RedTeam|\n",
      "|210086|  C18025|    C1493|    U748|   DOM1|RedTeam|\n",
      "|210294|  C18025|    C1493|    U748|   DOM1|RedTeam|\n",
      "|210312|  C18025|    C1493|    U748|   DOM1|RedTeam|\n",
      "|218418|  C17693|     C504|    U748|   DOM1|RedTeam|\n",
      "|227052|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "|227408|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "|227520|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "|227780|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "|228024|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "|228150|  C17693|     C148|    U748|   DOM1|RedTeam|\n",
      "+------+--------+---------+--------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "redteam.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-------+\n",
      "|time|auth_orient|success|\n",
      "+----+-----------+-------+\n",
      "|   1|      LogOn|Success|\n",
      "|   1|     LogOff|Success|\n",
      "|   1|     LogOff|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|     LogOff|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|     LogOff|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|     LogOff|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|     LogOff|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|      LogOn|Success|\n",
      "|   1|      LogOn|Success|\n",
      "+----+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auth.select('time','auth_orient','success').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol='strt', outputCol='successType')\n",
    "model = stringIndexer.fit(proc)\n",
    "indexed = model.transform(proc)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol='successType', outputCol='successVec')\n",
    "encoded = encoder.transform(indexed)\n",
    "encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_event = process_start.join(failed_logon, 'time','left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+\n",
      "|time| strt|proc_change|\n",
      "+----+-----+-----------+\n",
      "|   1|Start|        422|\n",
      "|   1|  End|         24|\n",
      "|   2|  End|         44|\n",
      "|   2|Start|       1451|\n",
      "|   3|  End|         42|\n",
      "|   3|Start|       1555|\n",
      "|   4|  End|         46|\n",
      "|   4|Start|        723|\n",
      "|   5|Start|        121|\n",
      "|   5|  End|         38|\n",
      "|   6|Start|         62|\n",
      "|   6|  End|         39|\n",
      "|   7|  End|         32|\n",
      "|   7|Start|         45|\n",
      "|   8|  End|          8|\n",
      "|   8|Start|         36|\n",
      "|   9|Start|         46|\n",
      "|   9|  End|         20|\n",
      "|  10|  End|          8|\n",
      "|  10|Start|         30|\n",
      "+----+-----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_start.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o182.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 8 (showString at NativeMethodAccessorImpl.java:0) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/blockmgr-621b0d97-28fd-4397-af15-9dff00553591/13/shuffle_0_87_0.data, offset=158734, length=2854} \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:528) \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:423) \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62) \tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434) \tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440) \tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) \tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30) \tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) \tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source) \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source) \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) \tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614) \tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) \tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125) \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96) \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53) \tat org.apache.spark.scheduler.Task.run(Task.scala:109) \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) \tat java.lang.Thread.run(Thread.java:745) Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/blockmgr-621b0d97-28fd-4397-af15-9dff00553591/13/shuffle_0_87_0.data, offset=158734, length=2854} \tat org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:114) \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:416) \t... 20 more Caused by: java.io.FileNotFoundException: /tmp/blockmgr-621b0d97-28fd-4397-af15-9dff00553591/13/shuffle_0_87_0.data (Too many open files) \tat java.io.FileInputStream.open(Native Method) \tat java.io.FileInputStream.<init>(FileInputStream.java:138) \tat org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:99) \t... 21 more \n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1348)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1869)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:363)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3278)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2489)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2489)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2489)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2703)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:254)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5059bde289df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaster_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o182.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 8 (showString at NativeMethodAccessorImpl.java:0) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/tmp/blockmgr-621b0d97-28fd-4397-af15-9dff00553591/13/shuffle_0_87_0.data, offset=158734, length=2854} \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:528) \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:423) \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62) \tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434) \tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440) \tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) \tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30) \tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) \tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source) \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source) \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) \tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614) \tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) \tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125) \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96) \tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53) \tat org.apache.spark.scheduler.Task.run(Task.scala:109) \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345) \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) \tat java.lang.Thread.run(Thread.java:745) Caused by: java.io.IOException: Error in opening FileSegmentManagedBuffer{file=/tmp/blockmgr-621b0d97-28fd-4397-af15-9dff00553591/13/shuffle_0_87_0.data, offset=158734, length=2854} \tat org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:114) \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:416) \t... 20 more Caused by: java.io.FileNotFoundException: /tmp/blockmgr-621b0d97-28fd-4397-af15-9dff00553591/13/shuffle_0_87_0.data (Too many open files) \tat java.io.FileInputStream.open(Native Method) \tat java.io.FileInputStream.<init>(FileInputStream.java:138) \tat org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:99) \t... 21 more \n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1348)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1869)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:363)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3278)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2489)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2489)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2489)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2703)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:254)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "master_event.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|time|count|\n",
      "+----+-----+\n",
      "|   1|   25|\n",
      "|   2|    7|\n",
      "|   3|    6|\n",
      "|   4|    3|\n",
      "|   6|    7|\n",
      "|   7|    3|\n",
      "|   8|    4|\n",
      "|  10|    5|\n",
      "|  11|    2|\n",
      "|  12|    3|\n",
      "|  13|    5|\n",
      "|  14|    2|\n",
      "|  15|    4|\n",
      "|  16|    9|\n",
      "|  17|    2|\n",
      "|  18|    4|\n",
      "|  19|    2|\n",
      "|  20|    5|\n",
      "|  21|    1|\n",
      "|  22|    3|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tgt_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|time|count|\n",
      "+----+-----+\n",
      "|   1|  422|\n",
      "|   2| 1451|\n",
      "|   3| 1555|\n",
      "|   4|  723|\n",
      "|   5|  121|\n",
      "|   6|   62|\n",
      "|   7|   45|\n",
      "|   8|   36|\n",
      "|   9|   46|\n",
      "|  10|   30|\n",
      "|  11|   19|\n",
      "|  12|   37|\n",
      "|  13|   29|\n",
      "|  14|   33|\n",
      "|  15|   20|\n",
      "|  16|   31|\n",
      "|  17|   28|\n",
      "|  18|   42|\n",
      "|  19|   19|\n",
      "|  20|   26|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_start.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|time|count|\n",
      "+----+-----+\n",
      "|   1|    8|\n",
      "|   2|    2|\n",
      "|   3|    2|\n",
      "|   4|    2|\n",
      "|   5|    1|\n",
      "|   6|    1|\n",
      "|   7|    1|\n",
      "|   8|    1|\n",
      "|  11|    1|\n",
      "|  12|    1|\n",
      "|  13|    1|\n",
      "|  14|    1|\n",
      "|  15|    1|\n",
      "|  16|    1|\n",
      "|  23|    1|\n",
      "|  25|    3|\n",
      "|  26|    2|\n",
      "|  29|    1|\n",
      "|  30|    2|\n",
      "|  31|    2|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "failed_logon.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc_domains = proc.select('domain').distinct()\n",
    "# proc_users = proc.select('user').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc_domains.coalesce(1).write.csv('domains.csv')\n",
    "# proc_users.coalesce(1).write.csv('users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+---------+-----+\n",
      "|time|user@domain|proc_name|start|\n",
      "+----+-----------+---------+-----+\n",
      "|   0|          0|        0|    0|\n",
      "+----+-----------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# proc.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in proc.columns)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-------+---------+--------+--------+-------+-------+\n",
      "|time|duration|src_comp|src_prt|dest_comp|dest_prt|protocol|pkt_cnt|byt_cnt|\n",
      "+----+--------+--------+-------+---------+--------+--------+-------+-------+\n",
      "| 530|     530|     530|    530|      530|     530|     530|    530|    530|\n",
      "+----+--------+--------+-------+---------+--------+--------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# flows.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in flows.columns)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|success|\n",
      "+-------+\n",
      "|Success|\n",
      "|   Fail|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auth.select('success').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+----------------+--------+---------+---------+----------+----------------+-------+\n",
      "|time|src_user@domain|dest_user@domain|src_comp|dest_comp|auth_type|logon_type|auth_orientation|success|\n",
      "+----+---------------+----------------+--------+---------+---------+----------+----------------+-------+\n",
      "|   0|              0|               0|       0|        0|        0|         0|               0|      0|\n",
      "+----+---------------+----------------+--------+---------+---------+----------+----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auth.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in auth.columns)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------+-------+---------+--------+--------+-------+-------+------------+\n",
      "| time|duration|src_comp|src_prt|dest_comp|dest_prt|protocol|pkt_cnt|byt_cnt|avg_pkt_size|\n",
      "+-----+--------+--------+-------+---------+--------+--------+-------+-------+------------+\n",
      "|41972|       0|   C1654|     80|   C13742|   N4427|       6|      2|     92|        46.0|\n",
      "|41974|      38|   C1015|   N221|    C8681|   N2153|       6|      2|     92|        46.0|\n",
      "|41972|       0|   C7632|   N294|   C20510|  N18962|       6|      1|     46|        46.0|\n",
      "|41970|       0|   C8974|  N4126|    C5787|  N30556|       6|      1|     46|        46.0|\n",
      "|41972|      38|   C1015|   N221|    C8964|   N2024|       6|      2|     92|        46.0|\n",
      "|41971|       0|  C14402|  N9113|     C585|     139|       6|      1|     46|        46.0|\n",
      "|41972|      60|  C11149|  N2801|    C2588|     N76|       6|      4|    184|        46.0|\n",
      "|41971|       0|   C3873|     80|    C3959|   N3771|       6|      2|     92|        46.0|\n",
      "|41973|       0|  C15166|  N5899|     C706|      80|       6|      1|     46|        46.0|\n",
      "|41971|       0|   C3959|  N3771|    C3873|      80|       6|      2|     92|        46.0|\n",
      "|41973|       0|  C20373|    445|   C11693|   N1037|       6|      1|     46|        46.0|\n",
      "|41971|       0|    C585|    445|     C947|   N6237|       6|      1|     46|        46.0|\n",
      "|41973|       0|   C4127| N16069|     C706|      80|       6|      1|     46|        46.0|\n",
      "|41971|      38|   C1015|   N221|     C184|   N2038|       6|      2|     92|        46.0|\n",
      "|41973|       0|   C7244| N18458|    C2008|     139|       6|      1|     46|        46.0|\n",
      "|41971|      60|   C7386|  N2843|    C2588|     N76|       6|      3|    138|        46.0|\n",
      "|41973|      60|   C2588|    N76|    C4905|    N179|       6|      3|    138|        46.0|\n",
      "|41973|      60|   C4905|   N179|    C2588|     N76|       6|      3|    138|        46.0|\n",
      "|41974|       0|   C8167|  N9273|     C585|     139|       6|      1|     46|        46.0|\n",
      "|41973|      60|   C9851|  N2783|    C2588|     N76|       6|      3|    138|        46.0|\n",
      "+-----+--------+--------+-------+---------+--------+--------+-------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flows.orderBy(\"avg_pkt_size\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-------+---------+--------+--------+-------+-------+------------+\n",
      "|time|duration|src_comp|src_prt|dest_comp|dest_prt|protocol|pkt_cnt|byt_cnt|avg_pkt_size|\n",
      "+----+--------+--------+-------+---------+--------+--------+-------+-------+------------+\n",
      "|   0|       0|       0|      0|        0|       0|       0|      0|      0|           0|\n",
      "+----+--------+--------+-------+---------+--------+--------+-------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flows.select([count(when(isnan(c)|col(c).isNull(), c)).alias(c) for c in flows.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------------+\n",
      "|time|src_comp|cmp_resolved|\n",
      "+----+--------+------------+\n",
      "|   0|       0|           0|\n",
      "+----+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dns.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in dns.columns)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: date (nullable = true)\n",
      " |-- src_comp: string (nullable = true)\n",
      " |-- cmp_resolved: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dns.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----+---------+-----+\n",
      "|time|user@domain| comp|proc_name|start|\n",
      "+----+-----------+-----+---------+-----+\n",
      "|   1|   C1$@DOM1|   C1|      P16|Start|\n",
      "|   1|C1001$@DOM1|C1001|       P4|Start|\n",
      "|   1|C1002$@DOM1|C1002|       P4|Start|\n",
      "|   1|C1004$@DOM1|C1004|       P4|Start|\n",
      "|   1|C1017$@DOM1|C1017|       P4|Start|\n",
      "|   1|C1018$@DOM1|C1018|       P4|Start|\n",
      "|   1|C1020$@DOM1|C1020|       P3|Start|\n",
      "|   1|C1020$@DOM1|C1020|       P4|Start|\n",
      "|   1|C1028$@DOM1|C1028|      P16|  End|\n",
      "|   1|C1029$@DOM1|C1029|       P4|Start|\n",
      "|   1|C1030$@DOM1|C1030|       P4|Start|\n",
      "|   1|C1032$@DOM1|C1032|       P4|Start|\n",
      "|   1|C1035$@DOM1|C1035|      P37|Start|\n",
      "|   1|C1035$@DOM1|C1035|       P5|Start|\n",
      "|   1|C1051$@DOM1|C1051|      P16|Start|\n",
      "|   1|C1069$@DOM1|C1069|       P3|Start|\n",
      "|   1|C1069$@DOM1|C1069|       P4|Start|\n",
      "|   1|C1079$@DOM1|C1079|       P4|Start|\n",
      "|   1|C1084$@DOM1|C1084|       P4|Start|\n",
      "|   1|C1088$@DOM1|C1088|       P4|Start|\n",
      "+----+-----------+-----+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: date (nullable = true)\n",
      " |-- user@domain: string (nullable = true)\n",
      " |-- src_comp: string (nullable = true)\n",
      " |-- dst_comp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "redteam.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, unix_timestamp\n",
    "start = datetime.date(2018,1,1)\n",
    "#datetime.timestamp(2018,1,1,12,0,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 1, 3, 15, 22, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.fromtimestamp(time.mktime(start.timetuple()) + 228150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = udf (lambda x: datetime.datetime.fromtimestamp(time.mktime(start.timetuple()) + x).date(),DateType() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-48ac7615f935>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-48ac7615f935>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    redteam1 = redteam.withColumn(\"timestam\", redteam.select(\"time\")),'yyyy-MM-dd HH:mm:ss').cast(\"timestamp\") )\u001b[0m\n\u001b[1;37m                                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "redteam1 = redteam.withColumn(\"timestam\", redteam.select(\"time\")),'yyyy-MM-dd HH:mm:ss').cast(\"timestamp\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time_update = udf(lambda x: time.strftime('%m/%d %H:%M:%S', time.gmtime(x)))\n",
    "\n",
    "#timestam = time.strftime('%m/%d %H:%M:%S', time.gmtime(redteam.select(\"time\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|  time|      timestam|\n",
      "+------+--------------+\n",
      "|150885|01/02 17:54:45|\n",
      "|151036|01/02 17:57:16|\n",
      "|151648|01/02 18:07:28|\n",
      "|151993|01/02 18:13:13|\n",
      "|153792|01/02 18:43:12|\n",
      "|155219|01/02 19:06:59|\n",
      "|155399|01/02 19:09:59|\n",
      "|155460|01/02 19:11:00|\n",
      "|155591|01/02 19:13:11|\n",
      "|156658|01/02 19:30:58|\n",
      "|210086|01/03 10:21:26|\n",
      "|210294|01/03 10:24:54|\n",
      "|210312|01/03 10:25:12|\n",
      "|218418|01/03 12:40:18|\n",
      "|227052|01/03 15:04:12|\n",
      "|227408|01/03 15:10:08|\n",
      "|227520|01/03 15:12:00|\n",
      "|227780|01/03 15:16:20|\n",
      "|228024|01/03 15:20:24|\n",
      "|228150|01/03 15:22:30|\n",
      "+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "redteam1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
